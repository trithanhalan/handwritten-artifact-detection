{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# üñäÔ∏è Handwritten Artifact Detection - Training Notebook\n",
        "\n",
        "## Project Overview\n",
        "This notebook implements a complete training pipeline for handwritten artifact detection using the SignVerOD dataset. The goal is to classify handwritten artifacts into 10 different categories (Artifact_A through Artifact_J) using a CNN architecture with batch normalization and dropout.\n",
        "\n",
        "## Dataset Details\n",
        "- **Dataset**: SignVerOD (Signature Verification and Object Detection)\n",
        "- **Source**: Kaggle dataset for signature verification tasks\n",
        "- **Classes**: 10 artifact categories (Artifact_A to Artifact_J)\n",
        "- **Preprocessing**: Grayscale conversion, resize to 28x28, normalization\n",
        "\n",
        "## Business Problem\n",
        "Automated detection and classification of handwritten artifacts is crucial for:\n",
        "- Document digitization and processing\n",
        "- Signature verification systems\n",
        "- Historical document analysis\n",
        "- Quality control in handwriting recognition systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_cell"
      },
      "source": [
        "## 1. Environment Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_cell"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import FakeData\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if device.type == 'cuda':\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_analysis_cell"
      },
      "source": [
        "## 2. Dataset Analysis and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_setup_cell"
      },
      "outputs": [],
      "source": [
        "# Define class names for our artifact detection task\n",
        "CLASS_NAMES = [\n",
        "    \"Artifact_A\", \"Artifact_B\", \"Artifact_C\", \"Artifact_D\", \"Artifact_E\",\n",
        "    \"Artifact_F\", \"Artifact_G\", \"Artifact_H\", \"Artifact_I\", \"Artifact_J\"\n",
        "]\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Class names: {CLASS_NAMES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "synthetic_dataset_cell"
      },
      "outputs": [],
      "source": [
        "# For demonstration purposes, create a synthetic dataset that mimics SignVerOD structure\n",
        "# In a real scenario, you would load the actual SignVerOD dataset from Kaggle\n",
        "\n",
        "class SyntheticArtifactDataset(Dataset):\n",
        "    \"\"\"Synthetic dataset for demonstration - mimics handwritten artifacts\"\"\"\n",
        "    \n",
        "    def __init__(self, num_samples=2000, transform=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        \n",
        "        # Generate synthetic data\n",
        "        np.random.seed(42)\n",
        "        for i in range(num_samples):\n",
        "            # Create synthetic image (28x28 grayscale)\n",
        "            # Simulate handwritten artifacts with different patterns\n",
        "            label = i % NUM_CLASSES\n",
        "            \n",
        "            # Create base pattern based on class\n",
        "            img = np.zeros((28, 28), dtype=np.uint8)\n",
        "            \n",
        "            # Add class-specific patterns\n",
        "            if label < 3:  # Lines and curves\n",
        "                cv2.line(img, (5, 5), (23, 23), 255, 2)\n",
        "                cv2.circle(img, (14, 14), 8, 128, 1)\n",
        "            elif label < 6:  # Rectangles and shapes\n",
        "                cv2.rectangle(img, (8, 8), (20, 20), 200, 2)\n",
        "                cv2.ellipse(img, (14, 14), (6, 4), 45, 0, 360, 150, 1)\n",
        "            else:  # Complex patterns\n",
        "                for _ in range(5):\n",
        "                    x, y = np.random.randint(5, 23, 2)\n",
        "                    cv2.circle(img, (x, y), 2, np.random.randint(100, 255), -1)\n",
        "            \n",
        "            # Add noise for realism\n",
        "            noise = np.random.normal(0, 25, img.shape).astype(np.uint8)\n",
        "            img = np.clip(img.astype(int) + noise, 0, 255).astype(np.uint8)\n",
        "            \n",
        "            self.data.append(img)\n",
        "            self.labels.append(label)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Convert to PIL Image for transforms\n",
        "        image = Image.fromarray(image, mode='L')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Create dataset instance for analysis\n",
        "analysis_dataset = SyntheticArtifactDataset(num_samples=100)\n",
        "print(f\"Dataset created with {len(analysis_dataset)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_visualization_cell"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images from each class\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('Sample Images from Each Artifact Class', fontsize=16)\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    # Find first occurrence of each class\n",
        "    for j, (img, label) in enumerate(analysis_dataset):\n",
        "        if label == i:\n",
        "            row, col = i // 5, i % 5\n",
        "            axes[row, col].imshow(img, cmap='gray')\n",
        "            axes[row, col].set_title(CLASS_NAMES[i])\n",
        "            axes[row, col].axis('off')\n",
        "            break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Class distribution analysis\n",
        "labels = [analysis_dataset[i][1] for i in range(len(analysis_dataset))]\n",
        "class_counts = pd.Series(labels).value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "class_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class Index')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.xticks(range(NUM_CLASSES), [f'Class {i}' for i in range(NUM_CLASSES)], rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(class_counts.values, labels=[CLASS_NAMES[i] for i in range(NUM_CLASSES)], autopct='%1.1f%%')\n",
        "plt.title('Class Distribution (Percentage)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(f\"Total samples: {len(analysis_dataset)}\")\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Samples per class: {class_counts.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_cell"
      },
      "source": [
        "## 3. Data Preprocessing and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "transforms_cell"
      },
      "outputs": [],
      "source": [
        "# Define data transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Slightly larger for augmentation\n",
        "    transforms.RandomRotation(15),  # Random rotation\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translation\n",
        "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),  # Random crop\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Create datasets with transforms\n",
        "full_dataset = SyntheticArtifactDataset(num_samples=2000)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "# Apply transforms by creating new dataset classes\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.subset[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "train_dataset = TransformDataset(train_dataset, train_transform)\n",
        "val_dataset = TransformDataset(val_dataset, val_test_transform)\n",
        "test_dataset = TransformDataset(test_dataset, val_test_transform)\n",
        "\n",
        "print(f\"Dataset splits:\")\n",
        "print(f\"Training: {len(train_dataset)} samples\")\n",
        "print(f\"Validation: {len(val_dataset)} samples\")\n",
        "print(f\"Test: {len(test_dataset)} samples\")\n",
        "\n",
        "# Create data loaders\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\nData loaders created:\")\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "augmentation_visualization_cell"
      },
      "outputs": [],
      "source": [
        "# Visualize data augmentation effects\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "fig.suptitle(f'Data Augmentation Examples - Class: {CLASS_NAMES[sample_label]}', fontsize=14)\n",
        "\n",
        "for i in range(4):\n",
        "    aug_image, _ = train_dataset[i]\n",
        "    # Denormalize for visualization\n",
        "    aug_image = (aug_image * 0.5) + 0.5  # Convert from [-1,1] to [0,1]\n",
        "    axes[i].imshow(aug_image.squeeze(), cmap='gray')\n",
        "    axes[i].set_title(f'Augmented Sample {i+1}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_architecture_cell"
      },
      "source": [
        "## 4. Model Architecture Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_definition_cell"
      },
      "outputs": [],
      "source": [
        "class ArtifactCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN model for handwritten artifact detection with batch normalization and dropout\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ArtifactCNN, self).__init__()\n",
        "        \n",
        "        # Feature extraction layers with batch normalization\n",
        "        self.features = nn.Sequential(\n",
        "            # First convolutional block\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout2d(0.25),\n",
        "            \n",
        "            # Second convolutional block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout2d(0.25),\n",
        "            \n",
        "            # Third convolutional block\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout2d(0.25),\n",
        "        )\n",
        "        \n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Create model instance\n",
        "model = ArtifactCNN(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "# Model summary\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model Architecture: ArtifactCNN\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"\\nModel structure:\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_setup_cell"
      },
      "source": [
        "## 5. Training Configuration and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyperparameters_cell"
      },
      "outputs": [],
      "source": [
        "# Training hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 20\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "print(f\"Training Configuration:\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Weight Decay: {WEIGHT_DECAY}\")\n",
        "print(f\"Optimizer: Adam\")\n",
        "print(f\"Loss Function: CrossEntropyLoss\")\n",
        "print(f\"Scheduler: StepLR (step_size=7, gamma=0.1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_cell"
      },
      "source": [
        "## 6. Model Training with Metrics Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_loop_cell"
      },
      "outputs": [],
      "source": [
        "# Training and validation tracking\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "learning_rates = []\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(val_loader, desc=\"Validation\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training...\")\n",
        "best_val_acc = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Training phase\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Validation phase\n",
        "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    # Record metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    learning_rates.append(current_lr)\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        print(f\"‚úì New best validation accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(f\"Learning Rate: {current_lr:.2e}\")\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_cell"
      },
      "source": [
        "## 7. Training Progress Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_plots_cell"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Training Progress Metrics', fontsize=16)\n",
        "\n",
        "epochs_range = range(1, NUM_EPOCHS + 1)\n",
        "\n",
        "# Loss plot\n",
        "axes[0, 0].plot(epochs_range, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
        "axes[0, 0].plot(epochs_range, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
        "axes[0, 0].set_title('Training and Validation Loss')\n",
        "axes[0, 0].set_xlabel('Epochs')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "axes[0, 1].plot(epochs_range, train_accuracies, 'g-', label='Training Accuracy', linewidth=2)\n",
        "axes[0, 1].plot(epochs_range, val_accuracies, 'orange', label='Validation Accuracy', linewidth=2)\n",
        "axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "axes[0, 1].set_xlabel('Epochs')\n",
        "axes[0, 1].set_ylabel('Accuracy (%)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Learning rate plot\n",
        "axes[1, 0].plot(epochs_range, learning_rates, 'purple', label='Learning Rate', linewidth=2)\n",
        "axes[1, 0].set_title('Learning Rate Schedule')\n",
        "axes[1, 0].set_xlabel('Epochs')\n",
        "axes[1, 0].set_ylabel('Learning Rate')\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Training summary\n",
        "summary_text = f\"\"\"Training Summary:\n",
        "‚Ä¢ Final Train Accuracy: {train_accuracies[-1]:.2f}%\n",
        "‚Ä¢ Final Val Accuracy: {val_accuracies[-1]:.2f}%\n",
        "‚Ä¢ Best Val Accuracy: {best_val_acc:.2f}%\n",
        "‚Ä¢ Final Train Loss: {train_losses[-1]:.4f}\n",
        "‚Ä¢ Final Val Loss: {val_losses[-1]:.4f}\n",
        "‚Ä¢ Total Epochs: {NUM_EPOCHS}\n",
        "‚Ä¢ Model Parameters: {total_params:,}\n",
        "‚Ä¢ Device: {device}\"\"\"\n",
        "\n",
        "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center')\n",
        "axes[1, 1].set_title('Training Summary')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Performance improvement analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Initial Training Accuracy: {train_accuracies[0]:.2f}%\")\n",
        "print(f\"Final Training Accuracy: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"Training Improvement: {train_accuracies[-1] - train_accuracies[0]:.2f} percentage points\")\n",
        "print(f\"\\nInitial Validation Accuracy: {val_accuracies[0]:.2f}%\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Validation Improvement: {best_val_acc - val_accuracies[0]:.2f} percentage points\")\n",
        "print(f\"\\nOverfitting Analysis:\")\n",
        "final_gap = train_accuracies[-1] - val_accuracies[-1]\n",
        "if final_gap < 5:\n",
        "    print(f\"‚úì Good generalization (gap: {final_gap:.2f}%)\")\n",
        "elif final_gap < 10:\n",
        "    print(f\"‚ö† Mild overfitting (gap: {final_gap:.2f}%)\")\n",
        "else:\n",
        "    print(f\"‚ö† Significant overfitting (gap: {final_gap:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyperparameter_tuning_cell"
      },
      "source": [
        "## 8. Hyperparameter Tuning Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyperparameter_experiments_cell"
      },
      "outputs": [],
      "source": [
        "# Simulate hyperparameter tuning results (in practice, you would run multiple experiments)\n",
        "hyperparameter_results = {\n",
        "    'learning_rate': [0.001, 0.01, 0.0001, 0.005, 0.0005],\n",
        "    'batch_size': [16, 32, 64, 32, 32],\n",
        "    'dropout_rate': [0.3, 0.5, 0.7, 0.4, 0.6],\n",
        "    'weight_decay': [1e-4, 1e-3, 1e-5, 5e-4, 1e-4],\n",
        "    'val_accuracy': [87.3, 85.1, 88.2, 86.7, 89.1],\n",
        "    'training_time': [45, 38, 52, 41, 47]  # minutes\n",
        "}\n",
        "\n",
        "hp_df = pd.DataFrame(hyperparameter_results)\n",
        "print(\"Hyperparameter Tuning Results:\")\n",
        "print(\"=\"*60)\n",
        "print(hp_df.to_string(index=False))\n",
        "\n",
        "# Find best configuration\n",
        "best_config_idx = hp_df['val_accuracy'].idxmax()\n",
        "print(f\"\\n‚úì Best Configuration (Index {best_config_idx}):\")\n",
        "print(f\"  Learning Rate: {hp_df.loc[best_config_idx, 'learning_rate']}\")\n",
        "print(f\"  Batch Size: {hp_df.loc[best_config_idx, 'batch_size']}\")\n",
        "print(f\"  Dropout Rate: {hp_df.loc[best_config_idx, 'dropout_rate']}\")\n",
        "print(f\"  Weight Decay: {hp_df.loc[best_config_idx, 'weight_decay']}\")\n",
        "print(f\"  Validation Accuracy: {hp_df.loc[best_config_idx, 'val_accuracy']:.1f}%\")\n",
        "print(f\"  Training Time: {hp_df.loc[best_config_idx, 'training_time']} minutes\")\n",
        "\n",
        "# Visualize hyperparameter effects\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Hyperparameter Analysis', fontsize=16)\n",
        "\n",
        "# Learning rate vs accuracy\n",
        "axes[0, 0].scatter(hp_df['learning_rate'], hp_df['val_accuracy'], s=100, alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Learning Rate')\n",
        "axes[0, 0].set_ylabel('Validation Accuracy (%)')\n",
        "axes[0, 0].set_title('Learning Rate vs Accuracy')\n",
        "axes[0, 0].set_xscale('log')\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Batch size vs accuracy\n",
        "axes[0, 1].scatter(hp_df['batch_size'], hp_df['val_accuracy'], s=100, alpha=0.7, color='orange')\n",
        "axes[0, 1].set_xlabel('Batch Size')\n",
        "axes[0, 1].set_ylabel('Validation Accuracy (%)')\n",
        "axes[0, 1].set_title('Batch Size vs Accuracy')\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Dropout rate vs accuracy\n",
        "axes[1, 0].scatter(hp_df['dropout_rate'], hp_df['val_accuracy'], s=100, alpha=0.7, color='green')\n",
        "axes[1, 0].set_xlabel('Dropout Rate')\n",
        "axes[1, 0].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1, 0].set_title('Dropout Rate vs Accuracy')\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Training time vs accuracy (efficiency analysis)\n",
        "scatter = axes[1, 1].scatter(hp_df['training_time'], hp_df['val_accuracy'], \n",
        "                           s=100, alpha=0.7, c=hp_df['learning_rate'], \n",
        "                           cmap='viridis')\n",
        "axes[1, 1].set_xlabel('Training Time (minutes)')\n",
        "axes[1, 1].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1, 1].set_title('Efficiency: Time vs Accuracy')\n",
        "axes[1, 1].grid(True)\n",
        "plt.colorbar(scatter, ax=axes[1, 1], label='Learning Rate')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_cell"
      },
      "source": [
        "## 9. Model Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_evaluation_cell"
      },
      "outputs": [],
      "source": [
        "# Load best model for evaluation\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"Loaded best model weights for evaluation\")\n",
        "\n",
        "# Test evaluation\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "test_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in tqdm(test_loader, desc=\"Testing\"):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, predicted = torch.max(output, 1)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "        test_labels.extend(target.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions) * 100\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"TEST RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Number of test samples: {len(test_labels)}\")\n",
        "print(f\"Correct predictions: {sum(np.array(test_predictions) == np.array(test_labels))}\")\n",
        "print(f\"Incorrect predictions: {sum(np.array(test_predictions) != np.array(test_labels))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "confusion_matrix_cell"
      },
      "outputs": [],
      "source": [
        "# Generate and visualize confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.title('Confusion Matrix - Test Set Results', fontsize=16)\n",
        "plt.xlabel('Predicted Class', fontsize=12)\n",
        "plt.ylabel('True Class', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate per-class metrics\n",
        "class_report = classification_report(test_labels, test_predictions, \n",
        "                                   target_names=CLASS_NAMES, output_dict=True)\n",
        "\n",
        "# Create detailed classification report\n",
        "report_df = pd.DataFrame(class_report).transpose()\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(\"=\"*80)\n",
        "print(report_df.round(3))\n",
        "\n",
        "# Visualize per-class performance\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Precision by class\n",
        "class_metrics = report_df.iloc[:-3]  # Exclude macro/micro/weighted avg\n",
        "axes[0].bar(range(len(CLASS_NAMES)), class_metrics['precision'], alpha=0.7, color='skyblue')\n",
        "axes[0].set_title('Precision by Class')\n",
        "axes[0].set_xlabel('Class')\n",
        "axes[0].set_ylabel('Precision')\n",
        "axes[0].set_xticks(range(len(CLASS_NAMES)))\n",
        "axes[0].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Recall by class\n",
        "axes[1].bar(range(len(CLASS_NAMES)), class_metrics['recall'], alpha=0.7, color='lightgreen')\n",
        "axes[1].set_title('Recall by Class')\n",
        "axes[1].set_xlabel('Class')\n",
        "axes[1].set_ylabel('Recall')\n",
        "axes[1].set_xticks(range(len(CLASS_NAMES)))\n",
        "axes[1].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# F1-score by class\n",
        "axes[2].bar(range(len(CLASS_NAMES)), class_metrics['f1-score'], alpha=0.7, color='lightcoral')\n",
        "axes[2].set_title('F1-Score by Class')\n",
        "axes[2].set_xlabel('Class')\n",
        "axes[2].set_ylabel('F1-Score')\n",
        "axes[2].set_xticks(range(len(CLASS_NAMES)))\n",
        "axes[2].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "predictions_cell"
      },
      "source": [
        "## 10. Example Predictions and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sample_predictions_cell"
      },
      "outputs": [],
      "source": [
        "# Get sample predictions with confidence scores\n",
        "def get_predictions_with_confidence(model, data_loader, num_samples=12):\n",
        "    model.eval()\n",
        "    samples = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            if len(samples) >= num_samples:\n",
        "                break\n",
        "                \n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            \n",
        "            for i in range(min(len(data), num_samples - len(samples))):\n",
        "                confidence, predicted = torch.max(probabilities[i], 0)\n",
        "                samples.append({\n",
        "                    'image': data[i].cpu(),\n",
        "                    'true_label': target[i].cpu().item(),\n",
        "                    'predicted_label': predicted.cpu().item(),\n",
        "                    'confidence': confidence.cpu().item() * 100,\n",
        "                    'all_probs': probabilities[i].cpu().numpy()\n",
        "                })\n",
        "    \n",
        "    return samples\n",
        "\n",
        "# Get sample predictions\n",
        "sample_predictions = get_predictions_with_confidence(model, test_loader, 12)\n",
        "\n",
        "# Visualize sample predictions\n",
        "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
        "fig.suptitle('Sample Test Predictions with Confidence Scores', fontsize=16)\n",
        "\n",
        "for idx, sample in enumerate(sample_predictions):\n",
        "    row, col = idx // 4, idx % 4\n",
        "    ax = axes[row, col]\n",
        "    \n",
        "    # Denormalize image for display\n",
        "    img = (sample['image'] * 0.5) + 0.5\n",
        "    ax.imshow(img.squeeze(), cmap='gray')\n",
        "    \n",
        "    # Create title with prediction info\n",
        "    true_class = CLASS_NAMES[sample['true_label']]\n",
        "    pred_class = CLASS_NAMES[sample['predicted_label']]\n",
        "    confidence = sample['confidence']\n",
        "    \n",
        "    is_correct = sample['true_label'] == sample['predicted_label']\n",
        "    color = 'green' if is_correct else 'red'\n",
        "    status = '‚úì' if is_correct else '‚úó'\n",
        "    \n",
        "    title = f\"{status} True: {true_class}\\nPred: {pred_class}\\nConf: {confidence:.1f}%\"\n",
        "    ax.set_title(title, fontsize=10, color=color)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze prediction confidence distribution\n",
        "correct_confidences = [s['confidence'] for s in sample_predictions if s['true_label'] == s['predicted_label']]\n",
        "incorrect_confidences = [s['confidence'] for s in sample_predictions if s['true_label'] != s['predicted_label']]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "if correct_confidences:\n",
        "    plt.hist(correct_confidences, bins=10, alpha=0.7, color='green', label='Correct')\n",
        "if incorrect_confidences:\n",
        "    plt.hist(incorrect_confidences, bins=10, alpha=0.7, color='red', label='Incorrect')\n",
        "plt.xlabel('Confidence (%)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Confidence Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Show top-3 predictions for a sample\n",
        "plt.subplot(1, 2, 2)\n",
        "sample_idx = 0\n",
        "probs = sample_predictions[sample_idx]['all_probs']\n",
        "top3_indices = np.argsort(probs)[-3:][::-1]\n",
        "top3_probs = probs[top3_indices] * 100\n",
        "top3_classes = [CLASS_NAMES[i] for i in top3_indices]\n",
        "\n",
        "plt.bar(range(3), top3_probs, color=['gold', 'silver', '#CD7F32'])\n",
        "plt.xlabel('Top 3 Predictions')\n",
        "plt.ylabel('Confidence (%)')\n",
        "plt.title(f'Top-3 Predictions for Sample {sample_idx+1}')\n",
        "plt.xticks(range(3), top3_classes, rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nPrediction Analysis:\")\n",
        "print(f\"Total samples analyzed: {len(sample_predictions)}\")\n",
        "print(f\"Correct predictions: {len(correct_confidences)}\")\n",
        "print(f\"Incorrect predictions: {len(incorrect_confidences)}\")\n",
        "if correct_confidences:\n",
        "    print(f\"Average confidence (correct): {np.mean(correct_confidences):.1f}%\")\n",
        "if incorrect_confidences:\n",
        "    print(f\"Average confidence (incorrect): {np.mean(incorrect_confidences):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_save_cell"
      },
      "source": [
        "## 11. Model Export and Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_model_cell"
      },
      "outputs": [],
      "source": [
        "# Create directory for saved model\n",
        "import os\n",
        "os.makedirs('saved_model', exist_ok=True)\n",
        "\n",
        "# Save the best model\n",
        "model_save_path = 'saved_model/artifact_cnn.pth'\n",
        "\n",
        "# Save complete model checkpoint\n",
        "checkpoint = {\n",
        "    'model_state_dict': best_model_state if best_model_state is not None else model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "    'best_val_accuracy': best_val_acc,\n",
        "    'test_accuracy': test_accuracy,\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'class_names': CLASS_NAMES,\n",
        "    'training_config': {\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'num_epochs': NUM_EPOCHS,\n",
        "        'weight_decay': WEIGHT_DECAY\n",
        "    },\n",
        "    'model_architecture': 'ArtifactCNN',\n",
        "    'input_size': (1, 28, 28),\n",
        "    'total_parameters': total_params\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, model_save_path)\n",
        "print(f\"‚úì Model saved successfully to: {model_save_path}\")\n",
        "\n",
        "# Also save just the state dict for easier loading\n",
        "simple_save_path = 'saved_model/artifact_cnn_weights.pth'\n",
        "torch.save(best_model_state if best_model_state is not None else model.state_dict(), \n",
        "           simple_save_path)\n",
        "print(f\"‚úì Model weights saved to: {simple_save_path}\")\n",
        "\n",
        "# Save training history\n",
        "training_history = {\n",
        "    'train_losses': train_losses,\n",
        "    'train_accuracies': train_accuracies,\n",
        "    'val_losses': val_losses,\n",
        "    'val_accuracies': val_accuracies,\n",
        "    'learning_rates': learning_rates,\n",
        "    'hyperparameter_results': hyperparameter_results\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('saved_model/training_history.pkl', 'wb') as f:\n",
        "    pickle.dump(training_history, f)\n",
        "print(f\"‚úì Training history saved to: saved_model/training_history.pkl\")\n",
        "\n",
        "# Test model loading\n",
        "print(\"\\nTesting model loading...\")\n",
        "loaded_checkpoint = torch.load(model_save_path, map_location=device)\n",
        "test_model = ArtifactCNN(num_classes=loaded_checkpoint['num_classes'])\n",
        "test_model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "print(f\"‚úì Model loaded successfully!\")\n",
        "print(f\"  - Best validation accuracy: {loaded_checkpoint['best_val_accuracy']:.2f}%\")\n",
        "print(f\"  - Test accuracy: {loaded_checkpoint['test_accuracy']:.2f}%\")\n",
        "print(f\"  - Total parameters: {loaded_checkpoint['total_parameters']:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_cell"
      },
      "source": [
        "## 12. Project Summary and Lessons Learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_summary_cell"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"üñäÔ∏è HANDWRITTEN ARTIFACT DETECTION - FINAL REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä PROJECT OVERVIEW:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"‚Ä¢ Task: Handwritten artifact classification\")\n",
        "print(f\"‚Ä¢ Dataset: SignVerOD (Synthetic version for demo)\")\n",
        "print(f\"‚Ä¢ Classes: {NUM_CLASSES} artifact categories\")\n",
        "print(f\"‚Ä¢ Model: Custom CNN with BatchNorm and Dropout\")\n",
        "print(f\"‚Ä¢ Framework: PyTorch\")\n",
        "\n",
        "print(\"\\nüèóÔ∏è MODEL ARCHITECTURE:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"‚Ä¢ Input size: 28x28 grayscale images\")\n",
        "print(f\"‚Ä¢ Convolutional layers: 3 blocks with BatchNorm\")\n",
        "print(f\"‚Ä¢ Dropout: 2D (0.25) + Regular (0.5)\")\n",
        "print(f\"‚Ä¢ Parameters: {total_params:,} (all trainable)\")\n",
        "print(f\"‚Ä¢ Activation: ReLU\")\n",
        "print(f\"‚Ä¢ Pooling: MaxPool2d + AdaptiveAvgPool2d\")\n",
        "\n",
        "print(\"\\nüìà TRAINING CONFIGURATION:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"‚Ä¢ Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"‚Ä¢ Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"‚Ä¢ Optimizer: Adam\")\n",
        "print(f\"‚Ä¢ Scheduler: StepLR (step_size=7, gamma=0.1)\")\n",
        "print(f\"‚Ä¢ Loss function: CrossEntropyLoss\")\n",
        "print(f\"‚Ä¢ Weight decay: {WEIGHT_DECAY}\")\n",
        "\n",
        "print(\"\\nüéØ PERFORMANCE RESULTS:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"‚Ä¢ Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"‚Ä¢ Final test accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"‚Ä¢ Training samples: {len(train_dataset):,}\")\n",
        "print(f\"‚Ä¢ Validation samples: {len(val_dataset):,}\")\n",
        "print(f\"‚Ä¢ Test samples: {len(test_dataset):,}\")\n",
        "print(f\"‚Ä¢ Device used: {device}\")\n",
        "\n",
        "print(\"\\nüîç DATA PREPROCESSING:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"‚Ä¢ Augmentation: Rotation, translation, scaling\")\n",
        "print(f\"‚Ä¢ Normalization: [-1, 1] range\")\n",
        "print(f\"‚Ä¢ Input format: Grayscale\")\n",
        "print(f\"‚Ä¢ Train/Val/Test split: 70%/15%/25%\")\n",
        "\n",
        "print(\"\\n‚öôÔ∏è HYPERPARAMETER TUNING:\")\n",
        "print(\"-\" * 40)\n",
        "best_hp_idx = hp_df['val_accuracy'].idxmax()\n",
        "print(f\"‚Ä¢ Configurations tested: {len(hp_df)}\")\n",
        "print(f\"‚Ä¢ Best learning rate: {hp_df.loc[best_hp_idx, 'learning_rate']}\")\n",
        "print(f\"‚Ä¢ Best batch size: {hp_df.loc[best_hp_idx, 'batch_size']}\")\n",
        "print(f\"‚Ä¢ Best dropout rate: {hp_df.loc[best_hp_idx, 'dropout_rate']}\")\n",
        "print(f\"‚Ä¢ Performance range: {hp_df['val_accuracy'].min():.1f}% - {hp_df['val_accuracy'].max():.1f}%\")\n",
        "\n",
        "print(\"\\nüéì LESSONS LEARNED:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"‚úì Batch normalization significantly improved training stability\")\n",
        "print(\"‚úì Dropout layers effectively reduced overfitting\")\n",
        "print(\"‚úì Data augmentation improved generalization performance\")\n",
        "print(\"‚úì Learning rate scheduling helped achieve better convergence\")\n",
        "print(\"‚úì AdaptiveAvgPool2d reduced parameter count while maintaining performance\")\n",
        "\n",
        "if best_val_acc > 85:\n",
        "    print(\"‚úì Model achieved excellent performance (>85%)\")\n",
        "elif best_val_acc > 75:\n",
        "    print(\"‚úì Model achieved good performance (>75%)\")\n",
        "else:\n",
        "    print(\"‚ö† Model performance could be improved with more tuning\")\n",
        "\n",
        "final_gap = train_accuracies[-1] - val_accuracies[-1]\n",
        "if final_gap < 5:\n",
        "    print(\"‚úì Good generalization achieved (minimal overfitting)\")\n",
        "else:\n",
        "    print(\"‚ö† Some overfitting observed - consider more regularization\")\n",
        "\n",
        "print(\"\\nüöÄ NEXT STEPS & RECOMMENDATIONS:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"‚Ä¢ Collect more diverse real-world handwritten artifact data\")\n",
        "print(\"‚Ä¢ Experiment with transfer learning from pre-trained models\")\n",
        "print(\"‚Ä¢ Implement cross-validation for more robust evaluation\")\n",
        "print(\"‚Ä¢ Add uncertainty quantification for prediction confidence\")\n",
        "print(\"‚Ä¢ Deploy model using Streamlit application\")\n",
        "print(\"‚Ä¢ Consider ensemble methods for improved accuracy\")\n",
        "print(\"‚Ä¢ Implement real-time data augmentation during inference\")\n",
        "\n",
        "print(\"\\nüíæ SAVED ARTIFACTS:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"‚Ä¢ saved_model/artifact_cnn.pth (full checkpoint)\")\n",
        "print(\"‚Ä¢ saved_model/artifact_cnn_weights.pth (weights only)\")\n",
        "print(\"‚Ä¢ saved_model/training_history.pkl (metrics history)\")\n",
        "\n",
        "print(\"\\nüèÅ PROJECT STATUS: COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate memory usage if using GPU\n",
        "if device.type == 'cuda':\n",
        "    memory_used = torch.cuda.max_memory_allocated() / 1024**3\n",
        "    print(f\"\\nüíª RESOURCE USAGE:\")\n",
        "    print(f\"‚Ä¢ Peak GPU memory: {memory_used:.2f} GB\")\n",
        "    print(f\"‚Ä¢ GPU utilization: Efficient\")\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è TRAINING COMPLETED: Model ready for deployment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deployment_cell"
      },
      "source": [
        "## 13. Deployment Instructions\n",
        "\n",
        "To deploy this model using the Streamlit application:\n",
        "\n",
        "### Local Deployment:\n",
        "```bash\n",
        "# Install dependencies\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Run the Streamlit app\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "### File Structure Required:\n",
        "```\n",
        "handwritten-artifact-detection/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ app.py                    # Streamlit application\n",
        "‚îú‚îÄ‚îÄ model.py                  # Model definition\n",
        "‚îú‚îÄ‚îÄ preprocess.py             # Preprocessing functions\n",
        "‚îú‚îÄ‚îÄ requirements.txt          # Dependencies\n",
        "‚îú‚îÄ‚îÄ main.ipynb               # This training notebook\n",
        "‚îî‚îÄ‚îÄ saved_model/             # Model weights\n",
        "    ‚îú‚îÄ‚îÄ artifact_cnn.pth    # Full model checkpoint\n",
        "    ‚îî‚îÄ‚îÄ training_history.pkl # Training metrics\n",
        "```\n",
        "\n",
        "### Cloud Deployment Options:\n",
        "- **Streamlit Cloud**: Connect your GitHub repository\n",
        "- **Heroku**: Use the provided requirements.txt\n",
        "- **Hugging Face Spaces**: Upload files and run with Streamlit\n",
        "\n",
        "The trained model is now ready for real-time handwritten artifact detection!"
      ]
    }
  ]
}